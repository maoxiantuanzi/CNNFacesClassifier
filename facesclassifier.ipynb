{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#读取原始图片并转化为numpy.ndarray，将灰度值由0～256转换到0～1:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = Image.open('olivettifaces.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_ndarray = np.asarray(img, dtype='float64')/256  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#图片大小是1190×942，一共20×20个人脸图，故每张人脸图大小为（1190/20）×（942/20）即57×47=2679  \n",
    "#将全部400个样本存储为一个400×2679的数组，每一行即代表一个人脸图，并且第0～9、10～19、20～29...行分别属于同个人脸  \n",
    "#另外，用<span style=\"font-family: SimSun;\">olivettifaces_label</span>表示每一个样本的类别，它是400维的向量，有0～39共40类，代表40个不同的人。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "olivettifaces=np.empty((400,2679))  \n",
    "for row in range(20):  \n",
    "    for column in range(20):  \n",
    "        olivettifaces[row*20+column]=np.ndarray.flatten(img_ndarray [row*57:(row+1)*57,column*47:(column+1)*47])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2679)\n"
     ]
    }
   ],
   "source": [
    "print(olivettifaces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#建一个<span style=\"font-family: SimSun;\">olivettifaces_label</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "olivettifaces_label=np.empty(400)  \n",
    "for label in range(40):  \n",
    "    olivettifaces_label[label*10:label*10+10]=label  \n",
    "olivettifaces_label=olivettifaces_label.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n"
     ]
    }
   ],
   "source": [
    "print(olivettifaces_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#保存olivettifaces以及olivettifaces_label到olivettifaces.pkl文件,这个文件存储了一个400×2679的向量和一个400×1的向量，代表样本及样本类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_file=open('olivettifaces.pkl','wb')    \n",
    "pickle.dump(olivettifaces,write_file,-1)    \n",
    "pickle.dump(olivettifaces_label,write_file,-1)    \n",
    "write_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要查看单张图片，必须先将代表图片的2679维的向量reshape，如：faces[1].reshape(57,47)。调用pylab显示图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD8CAYAAAAVHWrNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f370837a630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read_file=open('olivettifaces.pkl','rb')    \n",
    "faces=pickle.load(read_file)  \n",
    "read_file.close()   \n",
    "img1=faces[1].reshape(57,47)  \n",
    "pylab.imshow(img1)  \n",
    "pylab.gray()  \n",
    "pylab.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2679)\n"
     ]
    }
   ],
   "source": [
    "print(faces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取olivettifaces.pkl文件，分为训练集（40×8个样本），验证集（40×1个样本），测试集（40×1个样本）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_file=open('olivettifaces.pkl','rb')    \n",
    "faces=pickle.load(read_file)    \n",
    "label=pickle.load(read_file)    \n",
    "read_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=np.empty((320,2679))  \n",
    "train_label=np.empty(320)  \n",
    "valid_data=np.empty((40,2679))  \n",
    "valid_label=np.empty(40)  \n",
    "test_data=np.empty((40,2679))  \n",
    "test_label=np.empty(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(40):\n",
    "    train_data[i*8:i*8+8]=faces[i*10:i*10+8]\n",
    "    train_label[i*8:i*8+8]=label[i*10:i*10+8]\n",
    "    valid_data[i]=faces[i*10+8]\n",
    "    valid_label[i]=label[i*10+8]\n",
    "    test_data[i]=faces[i*10+9]\n",
    "    test_label[i]=label[i*10+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320, 2679)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x):    \n",
    "    # Hyperparameters\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    # TODO: Layer 1: Convolutional. Input = 57x47x1. Output = 53x43x5.\n",
    "    W1 = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 5), mean = mu, stddev = sigma)) # weight1, 初始化权重, 57-5+1=53\n",
    "    # W1.shape: [filter_height, filter_width, in_channels, out_channels]\n",
    "    # 具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]\n",
    "    #\n",
    "    # x：为需要做卷积的输入图像，它要求是一个Tensor，具有[batch, in_height, in_width, in_channels]这样的shape，\n",
    "    # 具体含义是[训练时一个batch的图片数量, 图片高度, 图片宽度, 图像通道数]，\n",
    "    # 注意这是一个4维的Tensor，要求类型为float32和float64其中之一\n",
    "    #\n",
    "    # strides：卷积时在图像每一维的步长，这是一个一维的向量，长度4\n",
    "    #\n",
    "    # padding：string类型的量，只能是\"SAME\",\"VALID\"其中之一，这个值决定了不同的卷积方式\n",
    "    x = tf.nn.conv2d(x, W1, strides=[1, 1, 1, 1], padding='VALID') # 实现卷积\n",
    "    b1 = tf.Variable(tf.zeros(5)) # bias1\n",
    "    x = tf.nn.bias_add(x, b1) # How does it work? the shape doesn't change\n",
    "    print(\"layer 1 shape:\",x.get_shape())\n",
    "\n",
    "    # TODO: Activation.\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    # TODO: Pooling. Input = 53x43x5. Output = 26x21x5.\n",
    "    # ksize: The size of the window for each dimension of the input tensor.\n",
    "    # strides: The stride of the sliding window for each dimension of the input tensor.\n",
    "    x = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    \n",
    "    # TODO: Layer 2: Convolutional. Output = 22x17x10.\n",
    "    W2 = tf.Variable(tf.truncated_normal(shape=(5, 5, 5, 10), mean = mu, stddev = sigma))\n",
    "    x = tf.nn.conv2d(x, W2, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    b2 = tf.Variable(tf.zeros(10))\n",
    "    x = tf.nn.bias_add(x, b2)\n",
    "                     \n",
    "    # TODO: Activation.\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    # TODO: Pooling. Input = 22x17x10. Output = 11x8x10.\n",
    "    x = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "\n",
    "    # TODO: Flatten. Input = 11x8x10. Output = 880.\n",
    "    x = flatten(x)\n",
    "    \n",
    "    # TODO: Layer 3: Fully Connected. Input = 880. Output = 120.\n",
    "    W3 = tf.Variable(tf.truncated_normal(shape=(880, 120), mean = mu, stddev = sigma))\n",
    "    b3 = tf.Variable(tf.zeros(120))    \n",
    "    x = tf.add(tf.matmul(x, W3), b3)\n",
    "    \n",
    "    # TODO: Activation.\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    # Dropout\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "\n",
    "    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    W4 = tf.Variable(tf.truncated_normal(shape=(120, 84), mean = mu, stddev = sigma))\n",
    "    b4 = tf.Variable(tf.zeros(84)) \n",
    "    x = tf.add(tf.matmul(x, W4), b4)\n",
    "    \n",
    "    # TODO: Activation.\n",
    "    x = tf.nn.relu(x)\n",
    "    \n",
    "    # Dropout\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "    print(\"x shape:\",x.get_shape())\n",
    "    # TODO: Layer 5: Fully Connected. Input = 84. Output = 40.\n",
    "    W5 = tf.Variable(tf.truncated_normal(shape=(84, 40), mean = mu, stddev = sigma))\n",
    "    b5 = tf.Variable(tf.zeros(40)) \n",
    "    logits = tf.add(tf.matmul(x, W5), b5)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 57, 47, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "keep_prob = tf.placeholder(tf.float32) # probability to keep units\n",
    "one_hot_y = tf.one_hot(y, 40)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1 shape: (?, 53, 43, 5)\n",
      "x shape: (?, 84)\n"
     ]
    }
   ],
   "source": [
    "rate = 0.0009\n",
    "\n",
    "logits = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate) #adam optimizer\n",
    "training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.0}) #keep_prob?\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a6f3351e1777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/random.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(self, x, random)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;31m# pick an element in x[:i+1] with which to exchange x[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(train_data)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = random.shuffle(train_data, train_label)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: 0.5})\n",
    "            \n",
    "        validation_accuracy = evaluate(valid_data, valid_label)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, 'lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
